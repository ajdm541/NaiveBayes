{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports and libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Training Data\n",
    "path = \"trg.csv\"\n",
    "#Pandas\n",
    "RawData = pd.read_csv(\"trg.csv\",index_col=0)\n",
    "RawData.head(n=10)\n",
    "\n",
    "#Not Pandas\n",
    "with open(\"trg.csv\") as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    data = list(readCSV)\n",
    "    data = data[1:]\n",
    "    data = np.array(data)\n",
    "#    print(data[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words:34095\n",
      "Total number of words after remove unique :14348\n",
      "{'B': 0.4005, 'A': 0.032, 'E': 0.536, 'V': 0.0315}\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing - PANDAS\n",
    "#Format - Uppercase letters\n",
    "RawData['abstract'] = RawData['abstract'].str.upper()\n",
    "\n",
    "\n",
    "#Remove negavite numbers and special characters (')\n",
    "RawData['abstract'] = RawData['abstract'].str.replace(r\"\\s(-*\\d*)*(-*\\d*)*$\\s|(-$)'\",'',regex=True)\n",
    "RawData['abstract'] = RawData['abstract'].str.replace(r\"\\s(-*\\d*)*\\s\",'',regex=True)\n",
    "RawData['abstract'] = RawData['abstract'].str.replace(r\"\\s(-?\\d+)\\s\",'',regex=True)\n",
    "RawData['abstract'] = RawData['abstract'].str.replace(\"'\",'',regex=False)\n",
    "\n",
    "#Split abstract string\n",
    "RawData['abstract'] = RawData['abstract'].str.split(' ')\n",
    "\n",
    "    \n",
    "#Remove common words and sort the array\n",
    "#Function to remove common words\n",
    "def removeCommon(array):\n",
    "    remove = ['THE','OF','A','AN','FOR','THAT','WITH','BY','AND',\n",
    "          'OR','IS','ARE','BY','WAS','WERE','IT','ITS', 'TO',\n",
    "             'WHICH', 'IN', 'HAVE', 'HAS', 'NO','NOT','AS', 'ALSO']\n",
    "    #Loop to remove common words & numeric values in the abstract\n",
    "    control=0\n",
    "    while control<len(array):\n",
    "        if array[control] in remove:\n",
    "            array.pop(control)\n",
    "        else:\n",
    "            if array[control].isnumeric():\n",
    "                array.pop(control)\n",
    "            else:\n",
    "                control += 1\n",
    "    #Return the sorted array    \n",
    "    array = array.sort()\n",
    "    return array\n",
    "\n",
    "#for word in remove:\n",
    "#    control=1\n",
    "#    while control<=len(array):\n",
    "#        if array[control] in remove:\n",
    "#            array.pop(word)\n",
    "#    while len(array)>0 and array.pop()=word or control>len(array):\n",
    "#        array.pop(word)\n",
    "#        control++\n",
    "        \n",
    "#Apply function to the column data\n",
    "RawData['abstract'].map(lambda x: removeCommon(x))\n",
    "\n",
    "#Words Collector\n",
    "# Identify different words in the abstracts \n",
    "# and count number of abstracts in which their appears \n",
    "def wordCollector(column):\n",
    "    globalWords = {}\n",
    "    for text in column:\n",
    "        rowWords = {}\n",
    "        for word in text:\n",
    "            if not word in rowWords.keys():\n",
    "                rowWords[word]=1;\n",
    "        for new in rowWords.keys():\n",
    "            if new in globalWords.keys():\n",
    "                globalWords[new] += 1\n",
    "            else:\n",
    "                globalWords[new] = 1\n",
    "    return globalWords\n",
    "\n",
    "allWords = wordCollector(RawData['abstract'])\n",
    "print(\"Total number of words:\" + str(len(allWords)))\n",
    "\n",
    "#Remove Outliers\n",
    "def removeUnique(allWords, limit=1):\n",
    "    words = list(allWords)\n",
    "    for word in words:\n",
    "        if allWords[word]<=limit:\n",
    "            allWords.pop(word)\n",
    "    return allWords       \n",
    "\n",
    "allWords = removeUnique(allWords, 1)\n",
    "print(\"Total number of words after remove unique :\" + str(len(allWords)))\n",
    "\n",
    "#Create and array with all words\n",
    "words = list(allWords)\n",
    "words.sort()\n",
    "\n",
    "#Create classes array\n",
    "classes = RawData['class'].unique()\n",
    "\n",
    "#Calculate probability of each class in the given class column of the dataset\n",
    "def classProbability(data):\n",
    "    classProbs = {}\n",
    "    classes = data.unique()\n",
    "    for c in classes:\n",
    "        classProbs[c] = data.where(data==c).count()/data.count()\n",
    "    return classProbs\n",
    "classprobs = classProbability(RawData['class'])\n",
    "print(classprobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words:29460\n",
      "Total number of words after remove unique :13082\n",
      "{'A': 0.032, 'B': 0.4005, 'E': 0.536, 'V': 0.0315}\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing - NO PANDAS\n",
    "#Format - Uppercase letters\n",
    "for row in data:\n",
    "    row[2]=row[2].upper()\n",
    "#    print(data[0:2])\n",
    "    \n",
    "#Remove negavite numbers and special characters (')\n",
    "for row in data:\n",
    "    row[2]=re.sub(r\"\\s(-*\\d*)*\\s\",' ',row[2])\n",
    "    row[2]=re.sub(r\"[']\",' ',row[2])\n",
    "\n",
    "#Split abstract string\n",
    "index = 0\n",
    "abstracts = {}\n",
    "for row in data:\n",
    "    abstracts[index] = np.array(row[2].split(' '))\n",
    "    index += 1\n",
    "    \n",
    "#Remove common words and sort the array\n",
    "#Function to remove common words\n",
    "def removeCommon(words):\n",
    "#List of common words\n",
    "    remove = ['THE','OF','A','AN','FOR','THAT','WITH','BY','AND',\n",
    "          'OR','IS','ARE','BY','WAS','WERE','IT','ITS', 'TO',\n",
    "             'WHICH', 'IN', 'HAVE', 'HAS', 'NO','NOT','AS', 'ALSO']\n",
    "#Loop to remove common words & numeric values in the abstract\n",
    "    control=0\n",
    "    while control<len(words):\n",
    "        if words[control] in remove:\n",
    "            words[control]=\"-DELETE-\"\n",
    "        control += 1\n",
    "    words = np.delete(words,np.argwhere(words=='-DELETE-')[:,0])\n",
    "#Return the sorted array    \n",
    "    words = np.sort(words)\n",
    "    return words\n",
    "       \n",
    "#Apply function to the column data\n",
    "for element in abstracts:\n",
    "    abstracts[element] = removeCommon(abstracts[element])\n",
    "\n",
    "#Words Collector\n",
    "# Identify different words in the abstracts \n",
    "# and count number of abstracts in which their appears (frequency in data instances - NOT Individual)\n",
    "def wordCollector(column):\n",
    "    globalWords = {}\n",
    "    for text in column:\n",
    "        rowWords = {}\n",
    "        for new in column[text]:\n",
    "            if not new in rowWords.keys():\n",
    "                rowWords[new]=1;\n",
    "        for word in rowWords.keys():\n",
    "            if word in globalWords.keys():\n",
    "                globalWords[word] += 1\n",
    "            else:\n",
    "                globalWords[word] = 1\n",
    "    return globalWords\n",
    "\n",
    "allWords = wordCollector(abstracts)\n",
    "#words = list(allWords)\n",
    "#words.sort()\n",
    "print(\"Total number of words:\" + str(len(allWords)))\n",
    "\n",
    "#Remove Outliers\n",
    "def removeUnique(allWords, limit=1):\n",
    "    words = list(allWords)\n",
    "    for word in words:\n",
    "        if allWords[word]<=limit:\n",
    "            allWords.pop(word)\n",
    "    return allWords       \n",
    "\n",
    "allWords = removeUnique(allWords, 1)\n",
    "print(\"Total number of words after remove unique :\" + str(len(allWords)))\n",
    "\n",
    "#Create and array with all words\n",
    "words = list(allWords)\n",
    "words.sort()\n",
    "\n",
    "#Create classes array\n",
    "classes = np.unique(data[:,1])\n",
    "\n",
    "#Calculate probability of each class in the given class column of the dataset\n",
    "def classProbability(classes):\n",
    "    classProbs = {}\n",
    "    uniqueClass = np.unique(classes)\n",
    "    for c in uniqueClass:\n",
    "        classProbs[c] = np.count_nonzero(classes==c)/classes.size\n",
    "#        classProbs[x] = classes.where(classes==c).count()/data.count()\n",
    "    return classProbs\n",
    "classProbs = classProbability(data[:,1])\n",
    "print(classProbs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training = np.asarray(list(abstracts.items()))\n",
    "#print(training[:2,1])\n",
    "#training = np.asarray(list(abstracts.items())[:10])\n",
    "#training = np.asarray(abstracts)\n",
    "\n",
    "#for row in data:\n",
    "#    row[2]=row[2].upper()\n",
    "\n",
    "#print(data[0:2])\n",
    "\n",
    "#classData = RawData.loc[RawData['class'] == 'E']\n",
    "#classData.head(n=5)\n",
    "#print(classData.size)\n",
    "\n",
    "#allWords = wordCollector(RawData['abstract'])\n",
    "#words = list(allWords)\n",
    "#words.sort()\n",
    "#print(words)\n",
    "#print(allWords)\n",
    "#RawData['abstract'].map(lambda x: removeCommon(x))\n",
    "#RawData['abstract'].head(n=10)\n",
    "#RawData.head(n=5)\n",
    "#new = removeCommon(RawData['abstract'][1])\n",
    "#print(new)\n",
    "\n",
    "#removeCommon(RawData['abstract'][1])\n",
    "#print(RawData['abstract'][1])\n",
    "\n",
    "    #classPriorProbs = np.zeros(len(targets))\n",
    "  #wordCount = len(dict.fromkeys(instances))\n",
    "\n",
    "    #for c in classPriorProbs:\n",
    "    #    c = np.zeros(len(words))\n",
    "\n",
    "    \n",
    "            #targetWords[target].pop('total')\n",
    "        #countClassWords = len(targetWords[target].keys())\n",
    "        \n",
    "        #        for prob in classPriorProbs[x]:   \n",
    "#            postProb[x] =+ instance.count()*math.log(classPriorProbs[x][prob])\n",
    "#        print(postProb)  \n",
    "#        print(classCount, classTotal)\n",
    "\n",
    "        #countClassWords = len(targetWords[target].keys())\n",
    "    \n",
    "    #training = np.asarray(list(abstracts.items())[:10])\n",
    "#training = np.asarray(abstracts)\n",
    "\n",
    "#print(training.loc[training['class']=='A']['abstract'])\n",
    "#print(classWords)\n",
    "#print(classWords.keys())\n",
    "#print(training['abstract'][1])\n",
    "\n",
    "\n",
    "\n",
    "#classData = RawData.loc[RawData['class'] == 'E']\n",
    "#training.head(n=10)\n",
    "#classData.head(n=5)\n",
    "\n",
    "#print(priorProbs)\n",
    "#print(training.loc[training['class']=='A']['abstract'])\n",
    "#print(classWords)\n",
    "#print(classWords.keys())\n",
    "#print(training['abstract'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1' 'B'\n",
      "  'THE 202 BP GENOME OF THE ALKALIPHILIC BACTERIUM BACILLUS HALODURANS C-125 CONTAINS PREDICTED PROTEIN CODING SEQUENCES CDSS 527 OF WHICH HAVE FUNCTIONAL ASSIGNMENTS 29 OF WHICH ARE CONSERVED CDSS WITH UNKNOWN FUNCTION AND 18 OF WHICH HAVE NO MATCH TO ANY PROTEIN DATABASE AMONG THE TOTAL CDSS MATCH SEQUENCES OF PROTEINS FOUND ONLY IN BACILLUS SUBTILIS AND ARE WIDELY CONSERVED IN COMPARISON WITH THE PROTEINS OF VARIOUS ORGANISMS INCLUDING BSUBTILIS THE B HALODURANS GENOME CONTAINS TRANSPOSASE GENES INDICATING THAT TRANSPOSASES HAVE PLAYED AN IMPORTANT EVOLUTIONARY ROLE IN HORIZONTAL GENE TRANSFER AND ALSO IN INTERNAL GENETIC REARRANGEMENT IN THE GENOME STRAIN C-125 LACKS SOME OF THE NECESSARY GENES FOR COMPETENCE SUCH AS COMS SRFA AND RAPC SUPPORTING THE FACT THAT COMPETENCE HAS NOT BEEN DEMONSTRATED EXPERIMENTALLY IN C-125 THERE IS NO PARALOG OF TUPA ENCODING TEICHURONOPEPTIDE WHICH CONTRIBUTES TO ALKALIPHILY IN THE C-125 GENOME AND AN ORTHOLOG OF TUPA CANNOT BE FOUND IN THE BSUBTILIS GENOME OUT OF SIGMA FACTORS WHICH BELONG TO THE EXTRACYTOPLASMIC FUNCTION FAMILY ARE UNIQUE TO B HALODURANS SUGGESTING THAT THEY MAY HAVE A ROLE IN THE SPECIAL MECHANISM OF ADAPTATION TO AN ALKALINE ENVIRONMENT']\n",
      " ['2' 'A'\n",
      "  'THE COMPLETE 1751377-BP SEQUENCE OF THE GENOME OF THE THERMOPHILIC ARCHAEON METHANOBACTERIUM THERMOAUTOTROPHICUM DELTAH HAS BEEN DETERMINED BY A WHOLE-GENOME SHOTGUN SEQUENCING APPROACH A TOTAL OF OPEN READING FRAMES ORFS HAVE BEEN IDENTIFIED THAT APPEAR TO ENCODE POLYPEPTIDES 46 OF WHICH HAVE BEEN ASSIGNED PUTATIVE FUNCTIONS BASED ON THEIR SIMILARITIES TO DATABASE SEQUENCES WITH ASSIGNED FUNCTIONS A TOTAL OF 28 OF THE ORF-ENCODED POLYPEPTIDES ARE RELATED TO SEQUENCES WITH UNKNOWN FUNCTIONS AND 27 HAVE LITTLE OR NO HOMOLOGY TO SEQUENCES IN PUBLIC DATABASES COMPARISONS WITH EUCARYA- BACTERIA- AND ARCHAEA-SPECIFIC DATABASES REVEAL THAT OF THE PUTATIVE GENE PRODUCTS ARE MOST SIMILAR TO POLYPEPTIDE SEQUENCES DESCRIBED PREVIOUSLY FOR OTHER ORGANISMS IN THE DOMAIN ARCHAEA COMPARISONS WITH THE METHANOCOCCUS JANNASCHII GENOME DATA UNDERLINE THE EXTENSIVE DIVERGENCE THAT HAS OCCURRED BETWEEN THESE TWO METHANOGENS ONLY 19 OF M THERMOAUTOTROPHICUM ORFS ENCODE SEQUENCES THAT ARE IDENTICAL TO M JANNASCHII POLYPEPTIDES AND THERE IS LITTLE CONSERVATION IN THE RELATIVE LOCATIONS OF ORTHOLOGOUS GENES WHEN THE M THERMOAUTOTROPHICUM ORFS ARE COMPARED TO SEQUENCES FROM ONLY THE EUCARYAL AND BACTERIAL DOMAINS 42 ARE MORE SIMILAR TO BACTERIAL SEQUENCES AND 13 ARE MORE SIMILAR TO EUCARYAL SEQUENCES THE BACTERIAL DOMAIN-LIKE GENE PRODUCTS INCLUDE THE MAJORITY OF THOSE PREDICTED TO BE INVOLVED IN COFACTOR AND SMALL MOLECULE BIOSYNTHESES INTERMEDIARY METABOLISM TRANSPORT NITROGEN FIXATION REGULATORY FUNCTIONS AND INTERACTIONS WITH THE ENVIRONMENT MOST PROTEINS PREDICTED TO BE INVOLVED IN DNA METABOLISM TRANSCRIPTION AND TRANSLATION ARE MORE SIMILAR TO EUCARYAL SEQUENCES GENE STRUCTURE AND ORGANIZATION HAVE FEATURES THAT ARE TYPICAL OF THE BACTERIA INCLUDING GENES THAT ENCODE POLYPEPTIDES CLOSELY RELATED TO EUCARYAL PROTEINS THERE ARE POLYPEPTIDES THAT COULD FORM TWO-COMPONENT SENSOR KINASE-RESPONSE REGULATOR SYSTEMS AND HOMOLOGS OF THE BACTERIAL HSP70-RESPONSE PROTEINS DNAK AND DNAJ WHICH ARE NOTABLY ABSENT IN M JANNASCHII DNA REPLICATION INITIATION AND CHROMOSOME PACKAGING IN M THERMOAUTOTROPHICUM ARE PREDICTED TO HAVE EUCARYAL FEATURES BASED ON THE PRESENCE OF TWO CDC6 HOMOLOGS AND THREE HISTONES HOWEVER THE PRESENCE OF AN FTSZ GENE INDICATES A BACTERIAL TYPE OF CELL DIVISION INITIATION THE DNA POLYMERASES INCLUDE AN X-FAMILY REPAIR TYPE AND AN UNUSUAL ARCHAEAL B TYPE FORMED BY TWO SEPARATE POLYPEPTIDES THE DNA-DEPENDENT RNA POLYMERASE RNAP SUBUNITS A  A B  B AND H ARE ENCODED IN A TYPICAL ARCHAEAL RNAP OPERON ALTHOUGH A SECOND A  SUBUNIT-ENCODING GENE IS PRESENT AT A REMOTE LOCATION THERE ARE TWO RRNA OPERONS AND TRNA GENES ARE DISPERSED AROUND THE GENOME ALTHOUGH MOST OF THESE OCCUR IN CLUSTERS THREE OF THE TRNA GENES HAVE INTRONS INCLUDING THE TRNAPRO GGG GENE WHICH CONTAINS A SECOND INTRON AT AN UNPRECEDENTED LOCATION THERE IS NO SELENOCYSTEINYL-TRNA GENE NOR EVIDENCE FOR CLASSICALLY ORGANIZED IS ELEMENTS PROPHAGES OR PLASMIDS THE GENOME CONTAINS ONE INTEIN AND TWO EXTENDED REPEATS AND KB THAT ARE MEMBERS OF A FAMILY WITH REPRESENTATIVES IN THE M JANNASCHII GENOME']\n",
      " ['3' 'E'\n",
      "  'IN WE STARTED ASSEMBLING AN ORDERED LIBRARY OF COSMID CLONES FROM CHROMOSOME XIV OF THE YEAST SACCHAROMYCES CEREVISIAE AT THAT TIME ONLY GENES WERE KNOWN TO BE LOCATED ON THIS CHROMOSOME AND WE ESTIMATED THAT TO OF ITS GENES WERE YET TO BE DISCOVERED IN A TEAM OF EUROPEAN LABORATORIES BEGAN THE SYSTEMATIC SEQUENCE ANALYSIS OF CHROMOSOME XIV THE COMPLETED AND INTENSIVELY CHECKED FINAL SEQUENCE OF BASE PAIRS WAS RELEASED IN APRIL SUBSTANTIAL PARTS HAD BEEN PUBLISHED BEFORE OR HAD PREVIOUSLY BEEN MADE AVAILABLE ON REQUEST THE SEQUENCE CONTAINED KNOWN OR PRESUMPTIVE PROTEIN-CODING GENES INCLUDING TWO PSEUDOGENES AND THREE RETROTRANSPOSONS TRNA GENES AND THREE SMALL NUCLEAR RNA GENES FOR 30 PROTEIN-CODING SEQUENCES ONE OR MORE STRUCTURAL HOMOLOGUES WERE IDENTIFIED ELSEWHERE IN THE YEAST GENOME HALF OF THEM BELONG TO DUPLICATED GROUPS OF LOOSELY LINKED GENES IN MOST CASES WITH CONSERVED GENE ORDER AND ORIENTATION RELAXED INTERCHROMOSOMAL SYNTENY WE HAVE CONSIDERED THE POSSIBLE EVOLUTIONARY ORIGINS OF THIS UNEXPECTED FEATURE OF YEAST GENOME ORGANIZATION']\n",
      " ['4' 'E'\n",
      "  'THE AIM OF THIS STUDY IS TO MEASURE HUMAN MITOCHONDRIAL SEQUENCE VARIABILITY IN THE RELATIVELY SLOWLY EVOLVING MITOCHONDRIAL GENE CYTOCHROME OXIDASE SUBUNIT II COII AND TO ESTIMATE WHEN THE HUMAN COMMON ANCESTRAL MITOCHONDRIAL TYPE EXISTED NEW COII GENE SEQUENCES WERE DETERMINED FOR FIVE HUMANS HOMO SAPIENS INCLUDING SOME OF THE MOST MITOCHONDRIALLY DIVERGENT HUMANS KNOWN FOR TWO PYGMY CHIMPANZEES PAN PANISCUS AND FOR A COMMON CHIMPANZEE P TROGLODYTES COII SEQUENCES WERE ANALYZED WITH THOSE FROM ANOTHER RELATIVELY SLOWLY EVOLVING MITOCHONDRIAL REGION ND4-5 FROM CLASS THIRD CODON POSITION SEQUENCE DATA A RELATIVE DIVERGENCE DATE FOR THE HUMAN MITOCHONDRIAL ANCESTOR IS ESTIMATED AS TH OF THE HUMAN-CHIMPANZEE DIVERGENCE TIME IF IT IS ASSUMED THAT HUMANS AND CHIMPANZEES DIVERGED MYA THIS PLACES A HUMAN MITOCHONDRIAL ANCESTOR AT YEARS SIGNIFICANTLY DIFFERENT FROM MYR THE PRESUMED TIME OF AN H ERECTUS EMERGENCE FROM AFRICA THE MEAN COALESCENT TIME ESTIMATED FROM ALL SITES OF COMBINED MITOCHONDRIAL DATA WHEN A 6-MYA HUMAN-CHIMPANZEE DIVERGENCE IS ASSUMED IS YEARS WITH CONFIDENCE INTERVAL OF YEARS NEITHER ESTIMATE IS COMPATIBLE WITH A 1-MYR-OLD HUMAN MITOCHONDRIAL ANCESTOR THE MITOCHONDRIAL DNA SEQUENCE DATA FROM COII AND ND4-5 REGIONS THEREFORE DO NOT SUPPORT THIS MULTIREGIONAL HYPOTHESIS FOR THE EMERGENCE OF MODERN HUMANS']\n",
      " ['5' 'B'\n",
      "  'THE AMINO ACID SEQUENCE OF THE SPIRULINA MAXIMA FERREDOXIN WAS SHOWN TO BE H2N-ALA-THR-TYR-LYS-VAL-THR-LEU-ILE-SER-GLU-ALA-GLU-GLY-ILE-ASN-GLU-THR-ILE-ASP-CYS-ASP-ASP-ASP-THR-TYR-ILE-LEU-ASP-ALA-ALA-GLU-GLU-ALA-GLY-LEU-ASP-LEU-PRO-TYR-SER-CYS-ARG-ALA-GLY-ALA-CYS-SER-THR-CYS-ALA-GLY-LYS-ILE-THR-SER-GLY-SER-ILE-ASP-GLN-SER-ASP-GLN-SER-PHE-LEU-ASP-ASP-ASP-GLN-ILE-GLN-ALA-GLY-TYR-VAL-LEU-THR-CYS-VAL-ALA-TYR-PRO-THR-SER-ASP-CYS-THR-ILE-GLN-THR-HIS-GLN-GLU-GLU-GLY-LEU-TYR-COOH THE S MAXIMA FERREDOXIN IS THE FIRST PROCARYOTE FERREDOXIN OF THE PLANT-ALGAL TYPE TO BE REPORTED A MODIFICATION OF THE AUTOMATED SEQUENCE DETERMINATION OF A PEPTIDE WHICH WAS EXTRACTED BY THE ORGANIC SOLVENTS USED TO REMOVE EXCESS REAGENTS AND THE AMINO ACID THIAZOLINE WAS UTILIZED TO COMPLETE THE SEQUENCE OF A RESIDUE TRYPTIC PEPTIDE']\n",
      " ['6' 'B'\n",
      "  'THE GENUS XANTHOMONAS IS A DIVERSE AND ECONOMICALLY IMPORTANT GROUP OF BACTERIAL PHYTOPATHOGENS BELONGING TO THE GAMMA-SUBDIVISION OF THE PROTEOBACTERIA XANTHOMONAS AXONOPODIS PV CITRI XAC CAUSES CITRUS CANKER WHICH AFFECTS MOST COMMERCIAL CITRUS CULTIVARS RESULTING IN SIGNIFICANT LOSSES WORLDWIDE SYMPTOMS INCLUDE CANKER LESIONS LEADING TO ABSCISSION OF FRUIT AND LEAVES AND GENERAL TREE DECLINE XANTHOMONAS CAMPESTRIS PV CAMPESTRIS XCC CAUSES BLACK ROT WHICH AFFECTS CRUCIFERS SUCH AS BRASSICA AND ARABIDOPSIS SYMPTOMS INCLUDE MARGINAL LEAF CHLOROSIS AND DARKENING OF VASCULAR TISSUE ACCOMPANIED BY EXTENSIVE WILTING AND NECROSIS XANTHOMONAS CAMPESTRIS PV CAMPESTRIS IS GROWN COMMERCIALLY TO PRODUCE THE EXOPOLYSACCHARIDE XANTHAN GUM WHICH IS USED AS A VISCOSIFYING AND STABILIZING AGENT IN MANY INDUSTRIES HERE WE REPORT AND COMPARE THE COMPLETE GENOME SEQUENCES OF XAC AND XCC THEIR DISTINCT DISEASE PHENOTYPES AND HOST RANGES BELIE A HIGH DEGREE OF SIMILARITY AT THE GENOMIC LEVEL MORE THAN OF GENES ARE SHARED AND GENE ORDER IS CONSERVED ALONG MOST OF THEIR RESPECTIVE CHROMOSOMES WE IDENTIFIED SEVERAL GROUPS OF STRAIN-SPECIFIC GENES AND ON THE BASIS OF THESE GROUPS WE PROPOSE MECHANISMS THAT MAY EXPLAIN THE DIFFERING HOST SPECIFICITIES AND PATHOGENIC PROCESSES']\n",
      " ['7' 'B'\n",
      "  'THE COMPLETE NUCLEOTIDE SEQUENCE OF THE GENOME OF A SYMBIOTIC BACTERIUM BRADYRHIZOBIUM JAPONICUM USDA110 WAS DETERMINED THE GENOME OF B JAPONICUM WAS A SINGLE CIRCULAR CHROMOSOME BP IN LENGTH WITH AN AVERAGE GC CONTENT OF NO PLASMID WAS DETECTED THE CHROMOSOME COMPRISES POTENTIAL PROTEIN-CODING GENES ONE SET OF RRNA GENES AND TRNA GENES FIFTY-TWO PERCENT OF THE POTENTIAL PROTEIN GENES SHOWED SEQUENCE SIMILARITY TO GENES OF KNOWN FUNCTION AND TO HYPOTHETICAL GENES THE REMAINING HAD NO APPARENT SIMILARITY TO REPORTED GENES THIRTY-FOUR PERCENT OF THE B JAPONICUM GENES SHOWED SIGNIFICANT SEQUENCE SIMILARITY TO THOSE OF BOTH MESORHIZOBIUM LOTI AND SINORHIZOBIUM MELILOTI WHILE WERE UNIQUE TO THIS SPECIES A PRESUMPTIVE SYMBIOSIS ISLAND KB IN LENGTH WHICH INCLUDES A 410-KB SYMBIOTIC REGION PREVIOUSLY REPORTED BY GTTFERT ET AL WAS IDENTIFIED SIX HUNDRED FIFTY-FIVE PUTATIVE PROTEIN-CODING GENES WERE ASSIGNED IN THIS REGION AND THE FUNCTIONS OF GENES INCLUDING THOSE RELATED TO SYMBIOTIC NITROGEN FIXATION AND DNA TRANSMISSION WERE DEDUCED A TOTAL OF GENES FOR TRANSPOSASES104 COPIES OF INSERTION SEQUENCES WERE IDENTIFIED IN THE GENOME IT WAS REMARKABLE THAT OUT OF TRANSPOSASE GENES ARE LOCATED IN THE PRESUMPTIVE SYMBIOTIC ISLAND DNA SEGMENTS OF TO KB INSERTED INTO TRNA GENES WERE FOUND AT LOCATIONS IN THE GENOME WHICH GENERATES PARTIAL DUPLICATION OF THE TARGET TRNA GENES THESE OBSERVATIONS SUGGEST PLASTICITY OF THE B JAPONICUM GENOME WHICH IS PROBABLY DUE TO COMPLEX GENOME REARRANGEMENTS SUCH AS HORIZONTAL TRANSFER AND INSERTION OF VARIOUS DNA ELEMENTS AND TO HOMOLOGOUS RECOMBINATION']\n",
      " ['8' 'B'\n",
      "  'THE COMPLETE GENOME SEQUENCE OF CAULOBACTER CRESCENTUS WAS DETERMINED TO BE BASE PAIRS IN A SINGLE CIRCULAR CHROMOSOME ENCODING GENES THIS ORGANISM WHICH GROWS IN A DILUTE AQUATIC ENVIRONMENT COORDINATES THE CELL DIVISION CYCLE AND MULTIPLE CELL DIFFERENTIATION EVENTS WITH THE ANNOTATED GENOME SEQUENCE A FULL DESCRIPTION OF THE GENETIC NETWORK THAT CONTROLS BACTERIAL DIFFERENTIATION CELL GROWTH AND CELL CYCLE PROGRESSION IS WITHIN REACH TWO-COMPONENT SIGNAL TRANSDUCTION PROTEINS ARE KNOWN TO PLAY A SIGNIFICANT ROLE IN CELL CYCLE PROGRESSION GENOME ANALYSIS REVEALED THAT THE C CRESCENTUS GENOME ENCODES A SIGNIFICANTLY HIGHER NUMBER OF THESE SIGNALING PROTEINS THAN ANY BACTERIAL GENOME SEQUENCED THUS FAR ANOTHER REGULATORY MECHANISM INVOLVED IN CELL CYCLE PROGRESSION IS DNA METHYLATION THE OCCURRENCE OF THE RECOGNITION SEQUENCE FOR AN ESSENTIAL DNA METHYLATING ENZYME THAT IS REQUIRED FOR CELL CYCLE REGULATION IS SEVERELY LIMITED AND SHOWS A BIAS TO INTERGENIC REGIONS THE GENOME CONTAINS MULTIPLE CLUSTERS OF GENES ENCODING PROTEINS ESSENTIAL FOR SURVIVAL IN A NUTRIENT POOR HABITAT INCLUDED ARE THOSE INVOLVED IN CHEMOTAXIS OUTER MEMBRANE CHANNEL FUNCTION DEGRADATION OF AROMATIC RING COMPOUNDS AND THE BREAKDOWN OF PLANT-DERIVED CARBON SOURCES IN ADDITION TO MANY EXTRACYTOPLASMIC FUNCTION SIGMA FACTORS PROVIDING THE ORGANISM WITH THE ABILITY TO RESPOND TO A WIDE RANGE OF ENVIRONMENTAL FLUCTUATIONS C CRESCENTUS IS TO OUR KNOWLEDGE THE FIRST FREE-LIVING ALPHA-CLASS PROTEOBACTERIUM TO BE SEQUENCED AND WILL SERVE AS A FOUNDATION FOR EXPLORING THE BIOLOGY OF THIS GROUP OF BACTERIA WHICH INCLUDES THE OBLIGATE ENDOSYMBIONT AND HUMAN PATHOGEN RICKETTSIA PROWAZEKII THE PLANT PATHOGEN AGROBACTERIUM TUMEFACIENS AND THE BOVINE AND HUMAN PATHOGEN BRUCELLA ABORTUS']\n",
      " ['9' 'V'\n",
      "  'THE COMPLETE DNA SEQUENCE OF THE A2 STRAIN OF POLYOMA VIRUS HAS BEEN DETERMINED IT CONSISTS OF BASE PAIRS THE SEQUENCE IS ANALYSED IN TERMS OF ITS CODING POTENTIAL AND SITES OF POSSIBLE FUNCTIONAL SIGNIFICANCE OR STRUCTURAL INTEREST THE POLYOMA VIRUS GENOME IS COMPARED WITH THOSE OF RELATED TUMOUR VIRUSES SIMIAN VIRUS AND BK VIRUS']\n",
      " ['10' 'B'\n",
      "  'THE COMPLETE GENOMIC SEQUENCE OF CORYNEBACTERIUM GLUTAMICUM ATCC WELL-KNOWN IN INDUSTRY FOR THE PRODUCTION OF AMINO ACIDS EG OF L-GLUTAMATE AND L-LYSINE WAS DETERMINED THE C GLUTAMICUM GENOME WAS FOUND TO CONSIST OF A SINGLE CIRCULAR CHROMOSOME COMPRISING BASE PAIRS SEVERAL DNA REGIONS OF UNUSUAL COMPOSITION WERE IDENTIFIED THAT WERE POTENTIALLY ACQUIRED BY HORIZONTAL GENE TRANSFER EG A SEGMENT OF DNA FROM C DIPHTHERIAE AND A PROPHAGE-CONTAINING REGION AFTER AUTOMATED AND MANUAL ANNOTATION PROTEIN-CODING GENES HAVE BEEN IDENTIFIED AND TO OF THESE FUNCTIONS WERE ASSIGNED BY HOMOLOGIES TO KNOWN PROTEINS THESE ANALYSES CONFIRM THE TAXONOMIC POSITION OF C GLUTAMICUM AS RELATED TO MYCOBACTERIA AND SHOW A BROAD METABOLIC DIVERSITY AS EXPECTED FOR A BACTERIUM LIVING IN THE SOIL AS AN EXAMPLE FOR BIOTECHNOLOGICAL APPLICATION THE COMPLETE GENOME SEQUENCE WAS USED TO RECONSTRUCT THE METABOLIC FLOW OF CARBON INTO A NUMBER OF INDUSTRIALLY IMPORTANT PRODUCTS DERIVED FROM THE AMINO ACID L-ASPARTATE']]\n"
     ]
    }
   ],
   "source": [
    "def probability(data)\n",
    "    words = data['abstract'].len()\n",
    "    words = data\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B': -12.97336932169116, 'A': -16.184723521634215, 'E': -15.429354947601855, 'V': -19.025625059801197}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'B'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Naive Bayes Model - PANDAS\n",
    "\n",
    "#General Functions\n",
    "\n",
    "#Calculate count of word for a given class\n",
    "def classWords(target, instances):\n",
    "    classWords = {}\n",
    "    classWords['total']=0\n",
    "    for text in instances:\n",
    "        for word in text:\n",
    "            if not word in classWords.keys():\n",
    "                classWords[word] = 1\n",
    "            else:\n",
    "                classWords[word] += 1\n",
    "            classWords['total']+=1\n",
    "    return classWords\n",
    "\n",
    "#Caculate the prior probabilities of an instances for all classes\n",
    "def rowProb(words, instances, targets, targetWords):\n",
    "    classPriorProbs = {}\n",
    "    #Data Vocabulary (Count of unique words)\n",
    "    wordCount = len(words)\n",
    "    abstractWords = dict.fromkeys(instances)\n",
    "# Evaluation per class\n",
    "    for target in targets:        \n",
    "        classPriorProbs[target] = {}\n",
    "        totalClassWords = targetWords[target]['total']\n",
    "#Evaluation of each word in the instances        \n",
    "        for word in abstractWords:\n",
    "            if not word in targetWords[target].keys():\n",
    "                classPriorProbs[target][word] = 1 / (totalClassWords + wordCount)\n",
    "            else:\n",
    "                classPriorProbs[target][word] = \\\n",
    "                (targetWords[target][word] + 1 ) / (totalClassWords + wordCount)\n",
    "    return classPriorProbs\n",
    "\n",
    "def postProbBasic():\n",
    "    return False\n",
    "\n",
    "#Calculate \n",
    "def postProb(instance, classPriorProbs,classColumn):\n",
    "    postProb = {}\n",
    "    words = {}\n",
    "# Count unique word of an instance\n",
    "    for word in dict.fromkeys(instance):\n",
    "        words[word] = instance.count(word)\n",
    "# Count unique words in a class\n",
    "    for x in classColumn.unique():\n",
    "        classCount = classColumn.where(classColumn==x).count()\n",
    "        classTotal = classColumn.count()\n",
    "        postProb[x] =+ math.log(classCount/classTotal)\n",
    "# Calculate posterior probability of instance\n",
    "        for word in words:\n",
    "            postProb[x] += words[word]*math.log(classPriorProbs[x][word])\n",
    " \n",
    "    return postProb\n",
    "\n",
    "def classCode(classes,postProb):\n",
    "    prediction = {}\n",
    "    pre = min(postProb, key=postProb.get)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "#Example\n",
    "#Select training\n",
    "training = RawData.loc[0:10]\n",
    "#Determine classes\n",
    "classes = RawData['class'].unique()\n",
    "#Get words count of instances of each class value\n",
    "classesWords = {}\n",
    "for x in classes:\n",
    "    classesWords[x] = classWords(x,training.loc[training['class']==x]['abstract'])\n",
    "\n",
    "priorProbs = rowProb(words,training['abstract'][1],classes,classesWords)\n",
    "\n",
    "classifier = postProb(training['abstract'][1], priorProbs,training['class'])\n",
    "print(classifier)\n",
    "max(classifier.keys(), key=(lambda k: classifier[k]))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B' 'A' 'E' 'E' 'B' 'B' 'B' 'B' 'V' 'B' 'E' 'B' 'B' 'E' 'B' 'B' 'B' 'E'\n",
      " 'B' 'E' 'E' 'E' 'E' 'B' 'E' 'B' 'B' 'E' 'E' 'E' 'E' 'E' 'B' 'B' 'V' 'E'\n",
      " 'E' 'E' 'B' 'A' 'E' 'E' 'B' 'B' 'B' 'B' 'E' 'E' 'E' 'B' 'B' 'E' 'E' 'B'\n",
      " 'E' 'E' 'E' 'B' 'B' 'B' 'E' 'E' 'E' 'B' 'E' 'E' 'B' 'E' 'B' 'B' 'V' 'E'\n",
      " 'B' 'E' 'E' 'E' 'E' 'E' 'E' 'E' 'B' 'B' 'E' 'E' 'B' 'B' 'E' 'V' 'B' 'E'\n",
      " 'E' 'E' 'E' 'E' 'B' 'B' 'E' 'B' 'B' 'A' 'E' 'B' 'E' 'B' 'A' 'B' 'E' 'E'\n",
      " 'E' 'E' 'A' 'E' 'B' 'B' 'B' 'B' 'B' 'B' 'V' 'B' 'E' 'E' 'B' 'B' 'E' 'E'\n",
      " 'B' 'E' 'B' 'E' 'E' 'E' 'B' 'E' 'B' 'B' 'E' 'B' 'B' 'B' 'E' 'E' 'B' 'E'\n",
      " 'E' 'E' 'E' 'E' 'E' 'E' 'E' 'B' 'E' 'B' 'E' 'B' 'E' 'E' 'E' 'B' 'E' 'E'\n",
      " 'E' 'B' 'B' 'E' 'E' 'E' 'E' 'E' 'E' 'B' 'E' 'B' 'B' 'B' 'E' 'E' 'E' 'E'\n",
      " 'E' 'B' 'B' 'B' 'E' 'B' 'B' 'E' 'B' 'V' 'B' 'E' 'B' 'E' 'E' 'B' 'B' 'E'\n",
      " 'E' 'E' 'E' 'B' 'B' 'E' 'B' 'E' 'E' 'B' 'E' 'V' 'V' 'E' 'E' 'E' 'B' 'E'\n",
      " 'E' 'E' 'B' 'B' 'E' 'E' 'B' 'E' 'B' 'E' 'E' 'E' 'B' 'E' 'E' 'B' 'B' 'B'\n",
      " 'B' 'B' 'E' 'B' 'B' 'E' 'B' 'E' 'B' 'E' 'B' 'E' 'E' 'E' 'E' 'E' 'E' 'E'\n",
      " 'E' 'B' 'E' 'E' 'E' 'B' 'E' 'E' 'B' 'B' 'E' 'E' 'B' 'E' 'E' 'B' 'E' 'A'\n",
      " 'B' 'E' 'B' 'E' 'E' 'B' 'B' 'E' 'E' 'E' 'E' 'E' 'B' 'A' 'B' 'B' 'E' 'B'\n",
      " 'E' 'B' 'E' 'B' 'E' 'E' 'E' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'E' 'B' 'B'\n",
      " 'E' 'B' 'B' 'A' 'E' 'E' 'B' 'E' 'E' 'B' 'E' 'E' 'E' 'B' 'E' 'E' 'E' 'B'\n",
      " 'B' 'B' 'A' 'E' 'B' 'V' 'E' 'E' 'E' 'E' 'E' 'V' 'B' 'B' 'E' 'B' 'E' 'E'\n",
      " 'E' 'B' 'E' 'E' 'E' 'E' 'E' 'B' 'A' 'B' 'V' 'B' 'E' 'E' 'B' 'B' 'E' 'E'\n",
      " 'B' 'E' 'V' 'A' 'E' 'E' 'E' 'E' 'B' 'E' 'E' 'B' 'V' 'E' 'B' 'E' 'E' 'E'\n",
      " 'E' 'E' 'B' 'E' 'B' 'E' 'E' 'V' 'B' 'E' 'E' 'B' 'B' 'E' 'B' 'E' 'E' 'B'\n",
      " 'A' 'E' 'B' 'E' 'B' 'E' 'E' 'B' 'B' 'B' 'B' 'E' 'B' 'B' 'A' 'E' 'E' 'E'\n",
      " 'E' 'E' 'E' 'B' 'B' 'E' 'E' 'A' 'B' 'E' 'B' 'B' 'E' 'B' 'E' 'E' 'B' 'E'\n",
      " 'E' 'B' 'E' 'E' 'E' 'E' 'B' 'E' 'E' 'E' 'B' 'B' 'E' 'E' 'E' 'E' 'E' 'B'\n",
      " 'B' 'B' 'E' 'E' 'E' 'E' 'E' 'E' 'B' 'B' 'A' 'E' 'E' 'B' 'E' 'E' 'E' 'B'\n",
      " 'E' 'E' 'B' 'E' 'E' 'E' 'E' 'E' 'B' 'E' 'A' 'B' 'E' 'E' 'E' 'B' 'V' 'B'\n",
      " 'E' 'B' 'E' 'B' 'B' 'E' 'E' 'E' 'B' 'B' 'E' 'E' 'B' 'E' 'E' 'E' 'B' 'E'\n",
      " 'E' 'B' 'B' 'B' 'B' 'B' 'B' 'E' 'B' 'E' 'E' 'E' 'E' 'E' 'B' 'B' 'E' 'E'\n",
      " 'B' 'E' 'E' 'B' 'E' 'B' 'B' 'E' 'B' 'B' 'B' 'B' 'V' 'E' 'B' 'E' 'E' 'E'\n",
      " 'E' 'E' 'E' 'B' 'B' 'B' 'E' 'V' 'B' 'B' 'B' 'E' 'B' 'B' 'E' 'B' 'A' 'E'\n",
      " 'B' 'E' 'B' 'E' 'E' 'E' 'E' 'A' 'B' 'B' 'B' 'E' 'A' 'E' 'V' 'E' 'B' 'B'\n",
      " 'A' 'B' 'B' 'E' 'B' 'E' 'E' 'E' 'E' 'B' 'E' 'B' 'B' 'B' 'E' 'E' 'E' 'B'\n",
      " 'B' 'B' 'E' 'E' 'B' 'E' 'B' 'E' 'B' 'B' 'B' 'E' 'V' 'E' 'E' 'B' 'E' 'E'\n",
      " 'E' 'B' 'B' 'B' 'E' 'B' 'E' 'B' 'B' 'B' 'E' 'E' 'E' 'B' 'B' 'E' 'E' 'E'\n",
      " 'B' 'E' 'E' 'E' 'E' 'B' 'B' 'E' 'B' 'E' 'E' 'E' 'E' 'B' 'B' 'E' 'E' 'B'\n",
      " 'B' 'E' 'B' 'B' 'B' 'B' 'E' 'B' 'B' 'B' 'E' 'B' 'E' 'E' 'E' 'B' 'E' 'B'\n",
      " 'A' 'E' 'E' 'B' 'V' 'E' 'B' 'E' 'A' 'E' 'E' 'E' 'E' 'B' 'E' 'E' 'B' 'B'\n",
      " 'B' 'B' 'E' 'E' 'E' 'E' 'E' 'B' 'E' 'E' 'E' 'E' 'B' 'B' 'B' 'B' 'E' 'E'\n",
      " 'E' 'E' 'B' 'E' 'V' 'V' 'E' 'E' 'E' 'B' 'E' 'B' 'E' 'B' 'E' 'B' 'E' 'B'\n",
      " 'E' 'E' 'B' 'E' 'B' 'B' 'E' 'E' 'E' 'E' 'E' 'E' 'E' 'A' 'B' 'B' 'A' 'E'\n",
      " 'E' 'B' 'E' 'E' 'B' 'B' 'E' 'B' 'B' 'A' 'E' 'B' 'E' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'E' 'E' 'B' 'E' 'E' 'B' 'E' 'E' 'E' 'E' 'E' 'B' 'E' 'E' 'B' 'E' 'E'\n",
      " 'E' 'E' 'B' 'E' 'B' 'E' 'B' 'E' 'B' 'B' 'E' 'B' 'B' 'B' 'B' 'A' 'B' 'B'\n",
      " 'E' 'B' 'E' 'E' 'E' 'B' 'B' 'E' 'E' 'B' 'E' 'E' 'E' 'B' 'B' 'E' 'E' 'B'\n",
      " 'E' 'E' 'E' 'E' 'E' 'E' 'B' 'E' 'E' 'B' 'E' 'E' 'B' 'E' 'E' 'E' 'B' 'B'\n",
      " 'E' 'E' 'E' 'E' 'E' 'B' 'B' 'E' 'A' 'E' 'E' 'E' 'E' 'B' 'B' 'B' 'E' 'E'\n",
      " 'B' 'E' 'B' 'B' 'E' 'E' 'E' 'B' 'E' 'B' 'B' 'E' 'V' 'B' 'B' 'E' 'E' 'E'\n",
      " 'E' 'E' 'E' 'B' 'E' 'E' 'B' 'E' 'E' 'B' 'E' 'E' 'B' 'E' 'E' 'B' 'B' 'E'\n",
      " 'E' 'B' 'B' 'B' 'E' 'E' 'E' 'E' 'E' 'B' 'B' 'B' 'B' 'E' 'E' 'E' 'E' 'B'\n",
      " 'E' 'E' 'B' 'E' 'E' 'E' 'E' 'E' 'B' 'E' 'B' 'B' 'E' 'B' 'E' 'B' 'E' 'B'\n",
      " 'E' 'B' 'E' 'E' 'E' 'E' 'E' 'B' 'A' 'E' 'B' 'B' 'E' 'E' 'E' 'B' 'E' 'E'\n",
      " 'B' 'B' 'B' 'E' 'E' 'E' 'B' 'B' 'E' 'B' 'E' 'E' 'E' 'B' 'E' 'E' 'E' 'B'\n",
      " 'B' 'E' 'E' 'E' 'E' 'B' 'E' 'B' 'B' 'B' 'E' 'B' 'E' 'E' 'B' 'E' 'B' 'B'\n",
      " 'E' 'B' 'B' 'B' 'B' 'B' 'B' 'E' 'V' 'E' 'E' 'E' 'E' 'E' 'E' 'B' 'B' 'B'\n",
      " 'E' 'A' 'E' 'A' 'E' 'B' 'B' 'B' 'B' 'B']\n",
      "['B' 'A' 'E' 'E' 'B' 'B' 'B' 'B' 'V' 'B' 'E' 'B' 'B' 'E' 'B' 'B' 'B' 'E'\n",
      " 'A' 'E' 'E' 'E' 'E' 'B' 'E' 'B' 'B' 'E' 'E' 'E' 'E' 'E' 'B' 'B' 'V' 'E'\n",
      " 'E' 'E' 'B' 'A' 'E' 'E' 'B' 'B' 'B' 'B' 'A' 'E' 'E' 'B' 'B' 'E' 'E' 'B'\n",
      " 'E' 'E' 'E' 'B' 'B' 'B' 'E' 'E' 'E' 'V' 'E' 'E' 'B' 'E' 'B' 'B' 'V' 'E'\n",
      " 'B' 'E' 'E' 'E' 'E' 'E' 'E' 'E' 'B' 'B' 'E' 'E' 'B' 'B' 'E' 'V' 'B' 'E'\n",
      " 'E' 'E' 'E' 'E' 'B' 'B' 'E' 'B' 'B' 'A' 'E' 'B' 'E' 'B' 'A' 'B' 'E' 'E'\n",
      " 'E' 'E' 'A' 'E' 'B' 'B' 'B' 'B' 'B' 'B' 'V' 'B' 'E' 'E' 'B' 'B' 'E' 'E'\n",
      " 'B' 'E' 'B' 'E' 'E' 'E' 'B' 'E' 'B' 'B' 'E' 'B' 'B' 'B' 'E' 'E' 'B' 'E'\n",
      " 'E' 'E' 'E' 'E' 'E' 'E' 'E' 'B' 'E' 'B' 'E' 'B' 'E' 'B' 'E' 'B' 'E' 'E'\n",
      " 'E' 'B' 'B' 'E' 'E' 'E' 'E' 'E' 'E' 'B' 'E' 'B' 'B' 'B' 'E' 'E' 'E' 'E'\n",
      " 'E' 'B' 'B' 'B' 'E' 'B' 'B' 'E' 'B' 'V' 'B' 'E' 'B' 'E' 'E' 'B' 'B' 'E'\n",
      " 'E' 'E' 'E' 'B' 'B' 'E' 'B' 'E' 'E' 'B' 'E' 'V' 'V' 'E' 'E' 'E' 'B' 'E'\n",
      " 'E' 'E' 'B' 'B' 'E' 'E' 'B' 'E' 'B' 'E' 'E' 'E' 'B' 'E' 'E' 'B' 'B' 'B'\n",
      " 'B' 'B' 'E' 'B' 'B' 'E' 'B' 'E' 'B' 'E' 'B' 'E' 'E' 'E' 'E' 'E' 'E' 'E'\n",
      " 'E' 'B' 'E' 'E' 'E' 'B' 'E' 'E' 'B' 'B' 'E' 'E' 'B' 'E' 'E' 'B' 'E' 'A'\n",
      " 'B' 'E' 'B' 'E' 'E' 'B' 'B' 'E' 'E' 'E' 'E' 'E' 'B' 'A' 'B' 'B' 'E' 'B'\n",
      " 'E' 'B' 'E' 'B' 'E' 'E' 'E' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'E' 'B' 'B'\n",
      " 'E' 'B' 'B' 'A' 'E' 'E' 'B' 'E' 'E' 'B' 'E' 'E' 'E' 'B' 'E' 'E' 'E' 'B'\n",
      " 'B' 'B' 'A' 'E' 'B' 'V' 'E' 'E' 'E' 'E' 'E' 'V' 'B' 'B' 'E' 'B' 'E' 'E'\n",
      " 'E' 'B' 'E' 'E' 'E' 'E' 'E' 'B' 'A' 'B' 'V' 'B' 'E' 'E' 'B' 'B' 'E' 'E'\n",
      " 'B' 'E' 'V' 'A' 'E' 'E' 'E' 'E' 'B' 'E' 'E' 'B' 'V' 'E' 'B' 'E' 'E' 'E'\n",
      " 'E' 'E' 'B' 'E' 'B' 'E' 'E' 'V' 'B' 'E' 'E' 'B' 'B' 'E' 'B' 'E' 'E' 'B'\n",
      " 'A' 'E' 'B' 'E' 'B' 'E' 'E' 'B' 'B' 'B' 'B' 'E' 'B' 'B' 'A' 'E' 'E' 'E'\n",
      " 'E' 'E' 'E' 'B' 'B' 'E' 'E' 'A' 'B' 'E' 'B' 'B' 'E' 'B' 'E' 'E' 'B' 'E'\n",
      " 'E' 'B' 'E' 'E' 'E' 'E' 'B' 'E' 'E' 'E' 'B' 'B' 'E' 'E' 'E' 'E' 'E' 'B'\n",
      " 'B' 'B' 'E' 'E' 'E' 'E' 'E' 'E' 'B' 'B' 'A' 'E' 'E' 'B' 'E' 'E' 'E' 'B'\n",
      " 'E' 'E' 'B' 'E' 'E' 'E' 'E' 'E' 'B' 'E' 'A' 'B' 'E' 'E' 'E' 'B' 'V' 'B'\n",
      " 'E' 'B' 'E' 'B' 'B' 'E' 'E' 'E' 'B' 'B' 'E' 'E' 'B' 'E' 'E' 'E' 'B' 'E'\n",
      " 'E' 'B' 'B' 'B' 'B' 'B' 'B' 'E' 'B' 'E' 'E' 'E' 'E' 'E' 'B' 'B' 'E' 'E'\n",
      " 'B' 'V' 'E' 'B' 'E' 'B' 'B' 'E' 'B' 'B' 'B' 'B' 'V' 'E' 'B' 'E' 'E' 'E'\n",
      " 'E' 'E' 'E' 'B' 'B' 'B' 'E' 'V' 'B' 'B' 'B' 'E' 'B' 'B' 'E' 'A' 'A' 'E'\n",
      " 'B' 'E' 'B' 'E' 'E' 'E' 'E' 'A' 'B' 'B' 'B' 'E' 'A' 'E' 'V' 'E' 'B' 'B'\n",
      " 'A' 'B' 'B' 'E' 'B' 'E' 'E' 'E' 'E' 'B' 'E' 'B' 'B' 'B' 'E' 'E' 'E' 'B'\n",
      " 'B' 'B' 'E' 'E' 'B' 'E' 'B' 'E' 'B' 'B' 'B' 'E' 'V' 'A' 'E' 'B' 'E' 'E'\n",
      " 'E' 'B' 'B' 'B' 'E' 'B' 'E' 'B' 'B' 'B' 'E' 'E' 'E' 'B' 'B' 'E' 'E' 'E'\n",
      " 'B' 'E' 'E' 'E' 'E' 'B' 'B' 'E' 'B' 'E' 'E' 'E' 'E' 'B' 'V' 'E' 'E' 'B'\n",
      " 'B' 'E' 'B' 'B' 'B' 'B' 'E' 'B' 'B' 'B' 'E' 'B' 'E' 'E' 'E' 'B' 'E' 'B'\n",
      " 'A' 'E' 'E' 'B' 'V' 'E' 'B' 'E' 'A' 'E' 'E' 'E' 'E' 'B' 'E' 'E' 'B' 'B'\n",
      " 'B' 'B' 'E' 'E' 'E' 'E' 'E' 'B' 'E' 'E' 'E' 'E' 'B' 'B' 'B' 'B' 'E' 'E'\n",
      " 'E' 'E' 'B' 'E' 'V' 'V' 'E' 'E' 'E' 'V' 'E' 'B' 'E' 'B' 'E' 'B' 'E' 'B'\n",
      " 'E' 'E' 'B' 'E' 'B' 'B' 'A' 'E' 'E' 'E' 'E' 'E' 'E' 'A' 'B' 'B' 'A' 'E'\n",
      " 'E' 'B' 'E' 'E' 'B' 'B' 'E' 'B' 'B' 'A' 'E' 'B' 'E' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'E' 'E' 'B' 'E' 'E' 'B' 'E' 'E' 'E' 'E' 'E' 'B' 'E' 'E' 'B' 'E' 'E'\n",
      " 'E' 'E' 'B' 'E' 'B' 'E' 'B' 'E' 'B' 'B' 'E' 'B' 'B' 'B' 'B' 'A' 'B' 'B'\n",
      " 'E' 'B' 'E' 'E' 'E' 'B' 'B' 'E' 'E' 'B' 'E' 'E' 'E' 'B' 'B' 'E' 'E' 'B'\n",
      " 'E' 'E' 'E' 'E' 'E' 'E' 'B' 'E' 'E' 'B' 'E' 'E' 'B' 'V' 'E' 'E' 'B' 'B'\n",
      " 'E' 'E' 'E' 'E' 'V' 'B' 'B' 'E' 'A' 'E' 'E' 'E' 'E' 'B' 'B' 'B' 'E' 'E'\n",
      " 'B' 'E' 'B' 'B' 'E' 'E' 'V' 'B' 'E' 'B' 'B' 'E' 'V' 'B' 'B' 'E' 'E' 'E'\n",
      " 'V' 'E' 'E' 'B' 'E' 'E' 'B' 'E' 'E' 'B' 'E' 'E' 'B' 'E' 'E' 'B' 'B' 'E'\n",
      " 'E' 'B' 'B' 'B' 'E' 'E' 'E' 'E' 'E' 'B' 'A' 'B' 'B' 'E' 'E' 'E' 'E' 'B'\n",
      " 'E' 'E' 'B' 'E' 'E' 'E' 'E' 'E' 'B' 'E' 'B' 'B' 'E' 'B' 'E' 'B' 'E' 'B'\n",
      " 'E' 'B' 'E' 'E' 'E' 'E' 'E' 'B' 'A' 'E' 'B' 'B' 'E' 'E' 'E' 'B' 'E' 'E'\n",
      " 'B' 'B' 'B' 'E' 'E' 'E' 'B' 'B' 'E' 'B' 'E' 'E' 'E' 'B' 'E' 'E' 'E' 'B'\n",
      " 'B' 'E' 'E' 'E' 'E' 'B' 'E' 'B' 'B' 'B' 'E' 'B' 'E' 'E' 'B' 'E' 'B' 'B'\n",
      " 'E' 'B' 'B' 'B' 'B' 'B' 'B' 'E' 'V' 'E' 'E' 'E' 'E' 'E' 'E' 'B' 'B' 'B'\n",
      " 'E' 'A' 'E' 'A' 'E' 'B' 'B' 'B' 'B' 'B']\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Model - NO PANDAS\n",
    "\n",
    "#General Functions\n",
    "\n",
    "#Calculate count of word of instances for a given class\n",
    "#target = class to count words\n",
    "#data = dataset\n",
    "#instances = index of instances of the target class\n",
    "def classWords(target, data, instances):\n",
    "    cWords = {}\n",
    "    cWords['total']=0\n",
    "    for row in instances:\n",
    "        for word in data[row][1]:\n",
    "            if not word in cWords.keys():\n",
    "                cWords[word] = 1\n",
    "            else:\n",
    "                cWords[word] += 1\n",
    "            cWords['total']+=1\n",
    "    return cWords\n",
    "\n",
    "#Calculate the prior probabilities of an instances for all classe\n",
    "#words = Vocabulary of the dataset\n",
    "#instance = instances | row evaluated\n",
    "#targets = predictable classes\n",
    "#targetwords = count of word of all instances of the same class\n",
    "def conditionalProb(words, instances, targets, targetWords):\n",
    "    classPriorProbs = {}\n",
    "#Data Vocabulary (Count of unique words)\n",
    "    wordCount = len(words)\n",
    "    abstractWords = np.unique(instances[1])\n",
    "# Evaluation per class\n",
    "    for target in targets:        \n",
    "        classPriorProbs[target] = {}\n",
    "        totalClassWords = targetWords[target]['total']\n",
    "        temp = targetWords[target].pop('total')\n",
    "\n",
    "#Evaluation of each word in the instances        \n",
    "        for word in abstractWords:\n",
    "            if not word in targetWords[target].keys():\n",
    "                classPriorProbs[target][word] = 1 / (totalClassWords + wordCount)\n",
    "            else:\n",
    "                classPriorProbs[target][word] = \\\n",
    "                (targetWords[target][word] + 1 ) / (totalClassWords + wordCount)\n",
    "        targetWords[target]['total']=temp\n",
    "    return classPriorProbs\n",
    "\n",
    "def postProbBasic():\n",
    "    return False\n",
    "\n",
    "#Classifier - Calculate class probability of and instance\n",
    "#instance = instance evaluated\n",
    "#condProb = conditional probabilities - classPriorProbs - prob of word for each class\n",
    "#priorProb = Prior probabilities for each class\n",
    "def classProb(instance, condProbs, priorProb):\n",
    "    postProb = {}\n",
    "    words = {}\n",
    "# Count unique word of an instance\n",
    "    for word in np.unique(instance[1]):        \n",
    "        words[word] = np.count_nonzero(instance[1]==word)\n",
    "# Count unique words in a class\n",
    "    for x in priorProb.keys():\n",
    "        postProb[x] = math.log(priorProb[x])\n",
    "# Calculate posterior probability of instance\n",
    "        for word in words:\n",
    "            postProb[x] += words[word]*math.log(condProbs[x][word])   \n",
    "    return postProb\n",
    "\n",
    "def classCode(classes,postProb):\n",
    "    prediction = {}\n",
    "    pre = min(postProb, key=postProb.get)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "#Example\n",
    "#Select training\n",
    "training = list(abstracts.items())[:1000]\n",
    "\n",
    "#Determine classes\n",
    "classes = np.unique(data[:,1])\n",
    "\n",
    "#Determine Instances\n",
    "numInstances = len(training)\n",
    "\n",
    "#Get words count of instances of each class value\n",
    "classesWords = {}\n",
    "for c in classes:\n",
    "    classesWords[c] = classWords(c, training, np.where(data[:numInstances]==c)[0])\n",
    "\n",
    "prediction =[]\n",
    "for elem in training:\n",
    "    \n",
    "#Get conditional probabilities of rows\n",
    "    condProbs = conditionalProb(words,training[elem[0]],classes,classesWords)\n",
    "\n",
    "#Classifier - Selecting a class\n",
    "    classifier = classProb(training[elem[0]], condProbs, classProbs)\n",
    "    #print(classifier)\n",
    "    prediction.append(max(classifier.keys(), key=(lambda k: classifier[k])))\n",
    "print(np.array(prediction))\n",
    "print(data[:numInstances,1])\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-Validation Test\n",
    "folds = 10\n",
    "cycle = 0\n",
    "performance = {}\n",
    "\n",
    "#Evaluate model performances with cross-validation\n",
    "#for(cycle; cycle<folds; cycle++)\n",
    "for x in DataTraining \n",
    "    testFold = DataTraining[cycle]\n",
    "    trainingFolds = DataTraining.pop(cycle)\n",
    "    performance[cycle] = runtest(trainingFolds, testFold)\n",
    "    cycle++ \n",
    "cycle = 0\n",
    "averagePerformance = np.sum(performance)/folds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Solution and Export to CSV\n",
    "RawData.to_cvs('amon897.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
